{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(1, 13, 1).reshape(3, 4).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6., 15., 24., 33.],\n",
      "        [ 6., 15., 24., 33.],\n",
      "        [ 6., 15., 24., 33.]]) tensor([[15., 15., 15.],\n",
      "        [18., 18., 18.],\n",
      "        [21., 21., 21.],\n",
      "        [24., 24., 24.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 13, 1).reshape(3, 4).float()\n",
    "b = torch.arange(1, 13, 1).reshape(4, 3).float()\n",
    "\n",
    "a.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "c = a @ b\n",
    "d = c.sum()\n",
    "\n",
    "d.backward()\n",
    "\n",
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]], requires_grad=True),\n",
       " tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]], dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]], dtype=torch.float16, grad_fn=<ToCopyBackward0>),\n",
       " tensor([[ 2.,  4.,  6.,  8.],\n",
       "         [10., 12., 14., 16.],\n",
       "         [18., 20., 22., 24.]], dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor(156., dtype=torch.float16, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = a.half()\n",
    "k = a.half()\n",
    "\n",
    "e = d + k\n",
    "f = e.sum()\n",
    "\n",
    "a, d, k, e, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True) tensor(10., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True)\n",
    "\n",
    "y = x.sum()  # y is a vector: tensor([4., 6.], grad_fn=<SumBackward1>)\n",
    "\n",
    "print(x, y)\n",
    "y.retain_grad = True\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1, 13, 1).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [10, 11, 12, 13]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a + 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) torch.Size([3, 2]) torch.Size([1, 2])\n",
      "tensor([[ 3.,  7., 11.]]) tensor([[1., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 3.]])\n",
      "torch.Size([1, 2]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 4, 1).reshape(1, 3).float()\n",
    "a.requires_grad = True\n",
    "b = torch.arange(1, 7, 1).reshape(3, 2).float()\n",
    "b.requires_grad = True\n",
    "\n",
    "c = a @ b\n",
    "c.retain_grad()\n",
    "print(a.shape, b.shape, c.shape)\n",
    "\n",
    "d = c.sum()\n",
    "d.retain_grad()\n",
    "d.backward()\n",
    "\n",
    "print(a.grad, b.grad)\n",
    "print(c.grad.shape, d.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_axis(left, right):\n",
    "    \"\"\"\n",
    "    mlx uses broadcasting before performing array ops\n",
    "    this function determines which axes on either arrays will be broadcasted\n",
    "    in order to calculate gradients along those axes.\n",
    "\n",
    "    example:\n",
    "    >>> left.shape = (3, 1)\n",
    "    >>> right.shape = (1, 4)\n",
    "    >>> broadcast_axis(left, right)     # ((1, ), (0, ))\n",
    "\n",
    "    here the second axis for left, and first axis for right will be broadcasted\n",
    "    \"\"\"\n",
    "    \n",
    "    ldim = len(left)\n",
    "    rdim = len(right)\n",
    "    maxdim = max(ldim, rdim)\n",
    "\n",
    "    lshape_new = (1, ) * (maxdim - ldim) + left\n",
    "    rshape_new = (1, ) * (maxdim - rdim) + right\n",
    "\n",
    "    assert len(lshape_new) == len(rshape_new)\n",
    "\n",
    "    left_axes, right_axes = [], []\n",
    "\n",
    "    for i in range(len(lshape_new)):\n",
    "        if lshape_new[i] > rshape_new[i]:\n",
    "            right_axes.append(i)\n",
    "        elif rshape_new[i] > lshape_new[i]:\n",
    "            left_axes.append(i)\n",
    "\n",
    "    return tuple(left_axes), tuple(right_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() ()\n",
      "() () ()\n",
      "--------\n",
      "[[ 3.  7. 11.]]\n",
      "[[1. 1.]\n",
      " [2. 2.]\n",
      " [3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "an = a.detach().numpy()\n",
    "bn = b.detach().numpy()\n",
    "cn = c.grad.detach().numpy()\n",
    "\n",
    "def get_expand_axis():\n",
    "    if an.ndim == 1:\n",
    "        a_expand_axis = (0, )\n",
    "    else:\n",
    "        a_expand_axis = ()\n",
    "\n",
    "    if bn.ndim == 1:\n",
    "        b_expand_axis = (-1, )\n",
    "    else:\n",
    "        b_expand_axis = ()\n",
    "\n",
    "    return a_expand_axis, b_expand_axis\n",
    "\n",
    "aa, ba = get_expand_axis()\n",
    "resa = aa + ba\n",
    "\n",
    "l, r = broadcast_axis(an.shape[:-2], bn.shape[:-2])\n",
    "\n",
    "print(l, r)\n",
    "\n",
    "print(aa, ba, resa)\n",
    "a_grad = np.reshape(np.sum(\n",
    "    np.expand_dims(cn, resa) @ np.expand_dims(bn, ba).swapaxes(-1, -2),\n",
    "    axis = l\n",
    "), an.shape)\n",
    "\n",
    "b_grad = np.reshape(np.sum(\n",
    "    np.expand_dims(an, aa).swapaxes(-1, -2) @ np.expand_dims(cn, resa),\n",
    "    axis = r\n",
    "), bn.shape)\n",
    "\n",
    "print(\"--------\")\n",
    "print(a_grad)\n",
    "print(b_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
